## ===경사하강법===

- ==**경사하강법이란?**==:**기울기를 보고 기울기가 줄어드는 쪽으로 가중치 값을 이동**.

- **기울기로 가중치의 값을 변경**.
	- 기울기에 따라 신호 세기가 바뀌고, 그에 따라 인공지능의 결괏값이 결정.
- **인공지능의 학습**=**가중치를 적절하게 수행하는 과정**.
- ![[3-4-2 인공 신경망 오차 줄이기-20240427214034883.webp|341]]
- **오차를 줄이려면** 가장 **오차가 작은 지점**으로 가중치를 **이동해야** 함.
- **y축이 높을 수록 기울기가 크며**,**꼭짓점으로 갈수록 기울기가 작아진다**.
- 우리가 **목표**로 하는 꼭짓점의 **기울기** = **0**


## 미분
- ![[3-4-2 인공 신경망 오차 줄이기-20240427220253007.webp|458]]
- **기울기가** **가파를수록** 다음 값의 **변화가 크다**는 것을 알 수 있고,**기울기가 완만할수록** 값의 **변화가 얼마 없다**는 것을 알 수 있다.
- 이러한 미분 개념을 사용하여 인공 신경망의 오차를 수정해 나간다.
- **경사 하강법의 핵심은 미분**이며, 이를 정확하게 이해하려면 일정 수준 이상의 수학 지식이 필요.~~[[2024-05-02- 수학 help🥕|살려줘]]~~


## 오차 역전파법(Back Propagation)

- ![[3-4-2 인공 신경망 오차 줄이기-20240427223436531.webp|358]]
- 오차 역전파법:오차를 끝에서부터 거꾸로 가면서 줄인다,마지막부터 처음까지 되돌아가면서 경사 하강법을 사용하여 각각의 가중치 값을 수정.

- 인공 신경망을 설계하면 가중치의 값이 한두 개가 아니라는 문제가 있다, 그 문제를 보안하기 위해 오차 역전파법이 나왔다.

- 뒤로 가면서 가중치를 수정한 다음 다시 한번 데이터를 흘려보낸 후 결괏값을 살펴봄.

- 그 결괏값이 정답값과 어떤 차이가 있는지 살펴본 후 다시 오차 역전파법을 사용하여 가중치를 수정.

- 인공 신경망은 이 과정을 반복하여 오차를 0으로 줄여나간다.

- 이렇게 오차값을 계산하고, 그 오차값에 따라 가중치를 점점 수정해나가는 모습이 바로 인공신경망에서의 인공지능 학습법이다.


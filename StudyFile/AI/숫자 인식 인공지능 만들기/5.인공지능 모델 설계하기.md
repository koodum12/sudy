#### 4개의 층으로 이루어져있다
- 첫 번째 층:입력층,데이터를 넣는 곳-784개로 지정
- 두 번째와 세 번째 층:은닉층-512 & 256개로 지정
- 네 번째 층:출력층으로 결과 출력-10개로 지정



#### 첫 번째층(입력층)이 784개인 이유
- 우리가 넣는 데이터의 모습이 784개의 데이터가 한줄로 이루어져있기 때문에 입력층의 뉴런의 수는 784개
- 앞에서 28\*28개 픽셀로 이루어진 숫자의 모습을 이렇게 바꾸었으며 이제 이 데이터를 딥러닝 모델에 넣을 예정. 
#### 두 번째층(은닉층)이 512개인 이유
의미 없음.
(추가로 첫 번째 은닉층에서 두 번째 은닉층으로 갈 때 활성화 함수는 ReLu함수 사용)
# <span></span>

```python
model = Sequential()
model.add(Dense(512,input_shape(784,)))
model.add(Activation('relu'))
model.add(Dense(256))
model.add(Activation('relu'))
model(Dense(10))
model(add(Activation('softmax')))
model.summary()
```
### model = Sequential()
- 딥러닝에 사용할 모델(model)을 시퀀셜 모델(Sequntial)로 정의

- 케라스는 시퀀셜 모델을 통해 이러한 형태의 딥러닝 모델을 쉽게 개발할 수 있도록 도와줌.
### model.add(Dense(512,input_shape = (784,)))
- 모델에 층을 추가한다 - 추가하는 명령어는 add

- 바로 앞에서 만든 딥러닝 모델(model)이 가지고 있는 함수를 사용하기때문에 model뒤에 점을 찍은 후 add 함수를 적는다,이때 층이 어떤 형태인지를 설정하기 위해 Dense함수를 사용

- Dense 함수의 첫 번째 인지는 해당 은닉층의 노드 수이며,두 번째 인자인 input_shape은 입력하는 데이터 형태

- 첫번째 은닉층 노드는 512개로 구성되어있다

### model.add(Activation('relu'))
- 다음 층으로 값을 전달할 때 어떤 활성화 함수를 사용하여 전달할지를 결정.
- 여기서 relu함수 사용
### model.add(Dense(256))
- 다음층 추가
- 두 번째 은닉층은 256개의 노드로 구성
- 두 번째 은닉층부터는 입력받는 노드를 설정할 필요가  **없다**
- 이러한 점이 케라스를 사용하는 이점
### softmax란?
각 노드에서 전달되는 값의 총 합이 1이 되도록 하기 위해 사용[[softmax 함수]]



### model.summary()
- summary 함수는 모델이 어떻게 구성되었는지 살펴보는 함수.
### 정리
- 시퀀셜 모델로 구성되어 있다.

- 레이어를 나타내는 Layer 부분과 레이어의 모습을 나타내는 Output Shape 부분,각 노드의 편향을 연결하는 가중치의 수를 나타내는 Param 부분으로 나누어져 있다

- 첫 번째 레이어는 512개의 노드로 이루어져 있으며,총 401920(784\*512+512)개의 파라미터로 이루어져 있다

- 바로 784개 입력층에서 512개의 은닉층으로 각각 연결 되어있어서 784\*512 개 만큼 가중치가 있고 은닉층 각 노드 수만큼 편향(512)이 있기 때문.

- 다음 레이어 256개의 노드로 구성,파라미터는 총 131328(512\*256+256)개 파라미터로 이루어져 있다.

- 마지막 레이어는 10개의 노드로 구성,파라미터는 2570(256\*10+10)개 파라미터로 이루어져 있다.


```python
model.compile(loss='categorical_crossentropy',optimizer = 'adam', metrics=['accuracy'])
model.fit(X_train,Y_train,batch_size=128,epochs=10,verbose=1)

```
- 신경망을 잘 학습시키려면 학습한 신경망이 분류한 값과 실제 값의 오차부터 계산해야 한다.
### model.compile(loss='categorical_crossentropy',optimizer = 'adam',merics=\['accuracy'])
- 케라스는 심층 신경망의 학습하는 방법을 정하는 명령어인 compile함수 제공
- ==compile 함수 사용을 위한 규칙==
	- 1,오차값을 계산하는 방법을 알려줘야 한다.
		- 이 인공지능은 이미지를 10개 중 하나로 분류해야 하므로 다중 분류 문제에 해당한다.
		- 그렇기 때문에 categorical_crossentropy 방법을 사용하면 된다.
	- 2.오차를 줄이는 방법을 알려주어야 한다
		- 오차를 줄이기 위해 옵티마이저(optimizer)를 사용,
		- 옵티마이저에는 다양한 방법이 있지만 여기에서는 adam이라는 방법을 사용한다.
		- [[Optimizer(옵티마이저)]] [[Optimizer(옵티마이저)#^42dc04|adam]]
	- 3.학습 결과를 어떻게 확인할지 알려줘야 한다.
### model.fit(X_train,Y_train,batch_size=128,epochs=10,verbose=1)
- 케라스는 학습시키기 위해 ' 맞춘다'는 의미를 가진 fit 함수를 제공
- fit 함수 사용하기 위한 규칙
	- 1.입력할 데이터를 정한다.
		- 우리는 X_train, Y_train 데이터를 사용하여 인공지능 모델을 학습하기 때문에 이 두가지를 넣는다.
	- 2.배치 사이즈(batch_size)를 정한다.
		- 배치 사이즈란 인공지능 모델이 한 번에 학습하는 데이터의 수를 의미
		- 여기에서는 한번에 128개 데이터를 학습시키므로 배치 사이즈는 128로 한다
	- 3.에포크(epochs)를 정한다.
		- 에포크는 모든 데이터를 1번 학습하는 것을 의미
		- 여기 있는 모든 데이터를 10번 반복해서 학습시킨다.(에포크는 10으로 ,verbose는 1로 설정한다)[[verbose]]
